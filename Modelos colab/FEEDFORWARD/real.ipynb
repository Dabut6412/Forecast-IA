{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hb1ArIkhjvZb","executionInfo":{"status":"ok","timestamp":1731822871280,"user_tz":360,"elapsed":41932,"user":{"displayName":"Daniel Brizuela","userId":"00306628851259003269"}},"outputId":"cecb3544-2503-4809-f954-a54496690fa4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Resultados:\n","\n","SKU: JSAB5\n","\n","Métricas de Retención (últimos 4 períodos):\n","MAD/Media: 0.04\n","RMSE: 37.41\n","\n","Predicciones de Retención:\n","Periodo 1: Actual: 717, Predicción: 734\n","Periodo 2: Actual: 816, Predicción: 749\n","Periodo 3: Actual: 727, Predicción: 755\n","Periodo 4: Actual: 742, Predicción: 748\n","\n","Predicciones Adicionales:\n","Periodo 5: Predicción: 732\n","Periodo 6: Predicción: 715\n","\n","Comparación de Historia Completa (36 períodos):\n","Periodo  |  Actual  |  Predicción\n","----------------------------------------\n","  01    |     517  |      517\n","  02    |     536  |      526\n","  03    |     575  |      543\n","  04    |     568  |      549\n","  05    |     614  |      552\n","  06    |     453  |      572\n","  07    |     572  |      572\n","  08    |     602  |      570\n","  09    |     669  |      587\n","  10    |     564  |      587\n","  11    |     623  |      587\n","  12    |     630  |      612\n","  13    |     613  |      626\n","  14    |     566  |      618\n","  15    |     599  |      618\n","  16    |     712  |      606\n","  17    |     667  |      606\n","  18    |     478  |      633\n","  19    |     676  |      633\n","  20    |     658  |      672\n","  21    |     726  |      662\n","  22    |     658  |      667\n","  23    |     684  |      667\n","  24    |     648  |      671\n","  25    |     726  |      671\n","  26    |     659  |      671\n","  27    |     693  |      672\n","  28    |     773  |      676\n","  29    |     716  |      710\n","  30    |     574  |      704\n","  31    |     791  |      704\n","  32    |     792  |      744\n","  33    |     717  |      754\n","  34    |     816  |      754\n","  35    |     727  |      792\n","  36    |     742  |      760\n","--------------------------------------------------\n","MAD/Media: 0.07\n","RMSE: 59.69\n","MAD/Media: 0.08\n","RMSE: 62.94\n","--------------------------------------------------\n","\n","SKU: JSAB12\n","\n","Métricas de Retención (últimos 4 períodos):\n","MAD/Media: 0.52\n","RMSE: 5.41\n","\n","Predicciones de Retención:\n","Periodo 1: Actual: 6, Predicción: 0\n","Periodo 2: Actual: 0, Predicción: 0\n","Periodo 3: Actual: 0, Predicción: 0\n","Periodo 4: Actual: 23, Predicción: 14\n","\n","Predicciones Adicionales:\n","Periodo 5: Predicción: 13\n","Periodo 6: Predicción: 14\n","\n","Comparación de Historia Completa (36 períodos):\n","Periodo  |  Actual  |  Predicción\n","----------------------------------------\n","  01    |       9  |        9\n","  02    |      12  |       10\n","  03    |       9  |       10\n","  04    |      17  |       12\n","  05    |      11  |       12\n","  06    |      12  |       11\n","  07    |       4  |       12\n","  08    |       2  |       11\n","  09    |       4  |        4\n","  10    |      19  |        4\n","  11    |      15  |        4\n","  12    |      18  |       15\n","  13    |       9  |       18\n","  14    |       0  |       15\n","  15    |      16  |        0\n","  16    |      13  |        0\n","  17    |       1  |        0\n","  18    |       2  |       13\n","  19    |       0  |        2\n","  20    |       1  |        0\n","  21    |       9  |        0\n","  22    |       4  |        0\n","  23    |      15  |        4\n","  24    |       0  |        9\n","  25    |       4  |        0\n","  26    |      16  |        0\n","  27    |       0  |        0\n","  28    |      23  |        0\n","  29    |       0  |        0\n","  30    |       0  |       20\n","  31    |       9  |        0\n","  32    |       4  |        0\n","  33    |       6  |        0\n","  34    |       0  |        6\n","  35    |       0  |        0\n","  36    |      23  |        0\n","--------------------------------------------------\n","MAD/Media: 0.93\n","RMSE: 9.98\n","MAD/Media: 0.81\n","RMSE: 10.54\n","--------------------------------------------------\n","\n","SKU: JSAB13\n","\n","Métricas de Retención (últimos 4 períodos):\n","MAD/Media: 0.49\n","RMSE: 16.20\n","\n","Predicciones de Retención:\n","Periodo 1: Actual: 9, Predicción: 25\n","Periodo 2: Actual: 58, Predicción: 33\n","Periodo 3: Actual: 18, Predicción: 31\n","Periodo 4: Actual: 25, Predicción: 25\n","\n","Predicciones Adicionales:\n","Periodo 5: Predicción: 22\n","Periodo 6: Predicción: 23\n","\n","Comparación de Historia Completa (36 períodos):\n","Periodo  |  Actual  |  Predicción\n","----------------------------------------\n","  01    |       9  |        9\n","  02    |      15  |       12\n","  03    |       4  |        9\n","  04    |      15  |       11\n","  05    |       6  |       15\n","  06    |       9  |        6\n","  07    |      13  |        9\n","  08    |       5  |        9\n","  09    |      15  |        9\n","  10    |      11  |       13\n","  11    |       5  |       11\n","  12    |       0  |       11\n","  13    |       4  |        0\n","  14    |       9  |        0\n","  15    |       4  |        0\n","  16    |      20  |        4\n","  17    |      13  |        9\n","  18    |       9  |       13\n","  19    |       1  |       13\n","  20    |       9  |        9\n","  21    |      11  |        9\n","  22    |      32  |        9\n","  23    |      23  |       11\n","  24    |      26  |       23\n","  25    |      23  |       26\n","  26    |      15  |       23\n","  27    |       4  |       23\n","  28    |       6  |       15\n","  29    |      20  |        6\n","  30    |      11  |        6\n","  31    |      11  |       11\n","  32    |       1  |       11\n","  33    |       9  |       11\n","  34    |      58  |        9\n","  35    |      18  |        9\n","  36    |      25  |       18\n","--------------------------------------------------\n","MAD/Media: 0.61\n","RMSE: 11.76\n","MAD/Media: 0.62\n","RMSE: 12.40\n","--------------------------------------------------\n","\n","Gráficas se encuentran en 'plots'.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import TimeSeriesSplit\n","import matplotlib.pyplot as plt\n","\n","\n","class RegularizedPredictor(nn.Module):\n","    def __init__(self, input_size=4, dropout_rate=0.2):\n","        super(RegularizedPredictor, self).__init__()\n","        self.fc = nn.Sequential(\n","            nn.Linear(input_size * 2, 32),\n","            nn.BatchNorm1d(32),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(32, 16),\n","            nn.BatchNorm1d(16),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(16, 6)\n","        )\n","\n","        self.l2_lambda = 0.01\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = x.view(batch_size, -1)\n","        return self.fc(x)\n","\n","    def get_l2_loss(self):\n","        l2_loss = 0\n","        for param in self.parameters():\n","            l2_loss += torch.norm(param, 2)\n","        return self.l2_lambda * l2_loss\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, min_delta=0):\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.best_loss = None\n","        self.early_stop = False\n","\n","    def __call__(self, val_loss):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","        elif val_loss > self.best_loss - self.min_delta:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_loss = val_loss\n","            self.counter = 0\n","\n","def train_with_validation(model, X_train, y_train, epochs=100, batch_size=32, validation_split=0.2):\n","    n_val = int(len(X_train) * validation_split)\n","    X_val = X_train[-n_val:]\n","    y_val = y_train[-n_val:]\n","    X_train = X_train[:-n_val]\n","    y_train = y_train[:-n_val]\n","\n","    train_dataset = torch.utils.data.TensorDataset(\n","        torch.FloatTensor(X_train),\n","        torch.FloatTensor(y_train)\n","    )\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True\n","    )\n","\n","    optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.01)\n","    criterion = nn.MSELoss()\n","    early_stopping = EarlyStopping(patience=5)\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        train_loss = 0\n","        for batch_X, batch_y in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(batch_X)\n","            loss = criterion(outputs, batch_y)\n","\n","            l2_loss = model.get_l2_loss()\n","            total_loss = loss + l2_loss\n","\n","            total_loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","\n","        model.eval()\n","        with torch.no_grad():\n","            val_outputs = model(torch.FloatTensor(X_val))\n","            val_loss = criterion(val_outputs, torch.FloatTensor(y_val))\n","\n","        early_stopping(val_loss)\n","        if early_stopping.early_stop:\n","            break\n","\n","    return model\n","\n","def prepare_sliding_windows(data, window_size=4):\n","    X, y = [], []\n","    for i in range(len(data) - window_size):\n","        X.append(data[i:i+window_size])\n","        y.append(data[i+window_size])\n","    return np.array(X), np.array(y)\n","\n","\n","def calculate_moving_stats(data, window=4):\n","    series = pd.Series(data)\n","    non_zero_series = series[series > 0]\n","\n","    if len(non_zero_series) > 0:\n","        non_zero_mean = non_zero_series.mean()\n","        non_zero_std = non_zero_series.std()\n","    else:\n","        non_zero_mean = 0\n","        non_zero_std = 0\n","\n","    trend = np.mean(np.diff(series)) if len(series) > 1 else 0\n","    zero_ratio = (series == 0).mean()\n","\n","    return non_zero_mean, non_zero_std, trend, zero_ratio\n","\n","def detect_zero_pattern(data):\n","    zeros = data == 0\n","    non_zero_indices = np.where(~zeros)[0]\n","    zero_indices = np.where(zeros)[0]\n","\n","    patterns = {\n","        'zero_ratio': zeros.mean(),\n","        'consecutive_zeros': any(zeros[i] and zeros[i+1] for i in range(len(zeros)-1)),\n","        'ends_with_zero': zeros[-1],\n","        'zero_runs': [],\n","        'non_zero_runs': [],\n","        'last_non_zero': data[~zeros][-1] if np.any(~zeros) else 0\n","    }\n","\n","    if len(non_zero_indices) > 0:\n","        patterns['non_zero_gaps'] = np.diff(non_zero_indices)\n","        patterns['avg_gap'] = np.mean(patterns['non_zero_gaps'])\n","        patterns['max_gap'] = np.max(patterns['non_zero_gaps'])\n","    else:\n","        patterns['avg_gap'] = len(data)\n","        patterns['max_gap'] = len(data)\n","\n","    current_run = 1\n","    for i in range(1, len(data)):\n","        if data[i] == 0 and data[i-1] == 0:\n","            current_run += 1\n","        elif data[i] == 0:\n","            patterns['zero_runs'].append(current_run)\n","            current_run = 1\n","        elif data[i] != 0 and data[i-1] != 0:\n","            current_run += 1\n","        else:\n","            patterns['non_zero_runs'].append(current_run)\n","            current_run = 1\n","\n","    patterns['avg_zero_run'] = np.mean(patterns['zero_runs']) if patterns['zero_runs'] else 1\n","    patterns['avg_non_zero_run'] = np.mean(patterns['non_zero_runs']) if patterns['non_zero_runs'] else 1\n","\n","    return patterns\n","\n","def calculate_safe_correlation(data1, data2):\n","    if len(data1) != len(data2):\n","        return 0\n","\n","    std1 = np.std(data1)\n","    std2 = np.std(data2)\n","\n","    if std1 == 0 or std2 == 0:\n","        if std1 == 0 and std2 == 0:\n","            return 1.0 if np.array_equal(data1, data2) else 0.0\n","        return 0.0\n","\n","    try:\n","        with np.errstate(divide='ignore', invalid='ignore'):\n","            correlation = np.corrcoef(data1, data2)[0,1]\n","            return correlation if not np.isnan(correlation) else 0.0\n","    except:\n","        return 0.0\n","\n","def calculate_stats(data):\n","    if len(data) == 0:\n","        return {\n","            'is_zero_heavy': False,\n","            'is_stable': False,\n","            'zero_pattern': {\n","                'zero_ratio': 0,\n","                'last_non_zero': 0,\n","                'avg_gap': 0\n","            },\n","            'min_non_zero': 0,\n","            'median_non_zero': 0,\n","            'mean_non_zero': 0,\n","            'recent_value': 0,\n","            'recent_trend': 0,\n","            'volatility': 0,\n","            'seasonal_pattern': 0\n","        }\n","\n","    non_zero_data = data[data > 0]\n","\n","    zero_pattern = detect_zero_pattern(data)\n","\n","    recent_trend = 0\n","    if len(data) >= 3:\n","        diffs = np.diff(data[-3:])\n","        if len(diffs) > 0:\n","            recent_trend = np.mean(diffs)\n","\n","    stats = {\n","        'zero_pattern': zero_pattern,\n","        'min_non_zero': float(non_zero_data.min()) if len(non_zero_data) > 0 else 0,\n","        'median_non_zero': float(np.median(non_zero_data)) if len(non_zero_data) > 0 else 0,\n","        'mean_non_zero': float(np.mean(non_zero_data)) if len(non_zero_data) > 0 else 0,\n","        'recent_value': float(data[-1]) if len(data) > 0 else 0,\n","        'recent_trend': float(recent_trend),\n","        'volatility': float(np.std(non_zero_data) / np.mean(non_zero_data)) if len(non_zero_data) > 0 and np.mean(non_zero_data) > 0 else 0\n","    }\n","\n","    stats['is_zero_heavy'] = 0.3 <= zero_pattern['zero_ratio'] <= 0.7\n","    stats['is_stable'] = stats['volatility'] < 0.4\n","\n","    if len(data) >= 4:\n","        stats['seasonal_pattern'] = calculate_safe_correlation(data[:-2], data[2:])\n","    else:\n","        stats['seasonal_pattern'] = 0\n","\n","    return stats\n","\n","def detect_zero_pattern(data):\n","    if len(data) == 0:\n","        return {\n","            'zero_ratio': 0,\n","            'consecutive_zeros': False,\n","            'ends_with_zero': False,\n","            'zero_runs': [],\n","            'non_zero_runs': [],\n","            'last_non_zero': 0,\n","            'avg_gap': 0,\n","            'max_gap': 0,\n","            'regular_spacing': float('inf'),\n","            'is_alternating': False,\n","            'last_non_zero_position': -1\n","        }\n","\n","    zeros = data == 0\n","    non_zero_indices = np.where(~zeros)[0]\n","\n","    patterns = {\n","        'zero_ratio': float(np.mean(zeros)) if len(zeros) > 0 else 0,\n","        'consecutive_zeros': any(zeros[i] and zeros[i+1] for i in range(len(zeros)-1)) if len(zeros) > 1 else False,\n","        'ends_with_zero': bool(zeros[-1]) if len(zeros) > 0 else False,\n","        'zero_runs': [],\n","        'non_zero_runs': [],\n","        'last_non_zero': float(data[~zeros][-1]) if np.any(~zeros) else 0,\n","        'last_non_zero_position': int(non_zero_indices[-1]) if len(non_zero_indices) > 0 else -1\n","    }\n","\n","    if len(non_zero_indices) > 1:\n","        gaps = np.diff(non_zero_indices)\n","        patterns['avg_gap'] = float(np.mean(gaps))\n","        patterns['max_gap'] = float(np.max(gaps))\n","        patterns['regular_spacing'] = float(np.std(gaps) / patterns['avg_gap']) if patterns['avg_gap'] > 0 else float('inf')\n","    else:\n","        patterns['avg_gap'] = float(len(data)) if len(data) > 0 else 0\n","        patterns['max_gap'] = float(len(data)) if len(data) > 0 else 0\n","        patterns['regular_spacing'] = float('inf')\n","\n","    current_run = 1\n","    for i in range(1, len(data)):\n","        if data[i] == 0 and data[i-1] == 0:\n","            current_run += 1\n","        elif data[i] == 0:\n","            if current_run > 1:\n","                patterns['non_zero_runs'].append(current_run)\n","            current_run = 1\n","        elif data[i] != 0 and data[i-1] != 0:\n","            current_run += 1\n","        else:\n","            if current_run > 1:\n","                patterns['zero_runs'].append(current_run)\n","            current_run = 1\n","\n","    patterns['avg_zero_run'] = float(np.mean(patterns['zero_runs'])) if patterns['zero_runs'] else 1\n","    patterns['avg_non_zero_run'] = float(np.mean(patterns['non_zero_runs'])) if patterns['non_zero_runs'] else 1\n","\n","    if len(data) >= 4:\n","        alternating_count = sum(1 for i in range(len(data)-1) if (data[i] == 0) != (data[i+1] == 0))\n","        patterns['is_alternating'] = (alternating_count / (len(data)-1)) > 0.7 if len(data) > 1 else False\n","    else:\n","        patterns['is_alternating'] = False\n","\n","    return patterns\n","\n","def calculate_historical_variation(data):\n","    non_zero_data = data[data > 0]\n","    if len(non_zero_data) < 2:\n","        return 0\n","\n","    try:\n","        variations = np.diff(non_zero_data) / non_zero_data[:-1]\n","        variations = variations[~np.isnan(variations)]\n","        variations = variations[~np.isinf(variations)]\n","\n","        if len(variations) == 0:\n","            return 0\n","\n","        return float(np.std(variations))\n","    except:\n","        return 0\n","\n","def should_predict_zero(stats, position, periods_since_last_non_zero):\n","    zero_pattern = stats['zero_pattern']\n","\n","    if zero_pattern['is_alternating']:\n","        should_be_zero = (stats['recent_value'] > 0)\n","        base_score = 0.8 if should_be_zero else 0.2\n","    else:\n","        recent_weight = 0.6\n","        pattern_weight = 0.4\n","\n","        recent_factor = 1.2 if stats['recent_value'] == 0 else 0.8\n","        pattern_factor = zero_pattern['zero_ratio']\n","\n","        base_score = (recent_weight * recent_factor + pattern_weight * pattern_factor)\n","\n","        if periods_since_last_non_zero >= zero_pattern['avg_gap']:\n","            base_score *= 0.7\n","\n","        if zero_pattern['regular_spacing'] < 0.3:\n","            expected_position = (periods_since_last_non_zero + 1) % max(2, round(zero_pattern['avg_gap']))\n","            base_score *= 1.3 if expected_position == 0 else 0.7\n","\n","    position_factor = 1 + 0.2 * np.sin(position * np.pi / 3)\n","    final_score = base_score * position_factor\n","\n","    base_threshold = 0.45\n","    if zero_pattern['consecutive_zeros']:\n","        base_threshold *= 0.9\n","    if stats['is_stable']:\n","        base_threshold *= 1.1\n","\n","    threshold = base_threshold + 0.05 * np.sin(position * np.pi / 2)\n","\n","    return final_score > threshold\n","\n","def predict_non_zero_value(stats, position, historical_data):\n","    non_zero_data = historical_data[historical_data > 0]\n","\n","    if len(non_zero_data) == 0:\n","        return 1\n","\n","    avg_value = np.mean(non_zero_data)\n","    is_small_values = avg_value < 30\n","\n","    if is_small_values:\n","        recent_values = non_zero_data[-3:] if len(non_zero_data) >= 3 else non_zero_data\n","        base = np.median(recent_values)\n","\n","        value_range = np.ptp(non_zero_data)\n","        if value_range == 0:\n","            value_range = base * 0.4\n","\n","        variation = value_range * 0.25 * np.exp(-position * 0.3)\n","        position_effect = np.sin(position * np.pi / 3) * variation\n","\n","        prediction = base + position_effect\n","\n","        min_val = max(min(non_zero_data) * 0.8, 1)\n","        max_val = max(non_zero_data) * 1.2\n","\n","    else:\n","        if stats['zero_pattern']['last_non_zero'] > 0:\n","            recent_non_zero = stats['zero_pattern']['last_non_zero']\n","        else:\n","            recent_non_zero = stats['median_non_zero']\n","\n","        historical_variation = calculate_historical_variation(historical_data)\n","\n","        if stats['is_stable']:\n","            base = stats['median_non_zero']\n","            variation_factor = historical_variation * 0.3\n","        else:\n","            recent_weight = 0.7\n","            typical_weight = 0.3\n","            base = (recent_non_zero * recent_weight + stats['mean_non_zero'] * typical_weight)\n","            variation_factor = historical_variation * 0.35\n","\n","        position_effect = np.sin(position * np.pi / 4) * variation_factor\n","        trend_adjustment = stats['recent_trend'] * position * 0.02\n","\n","        prediction = base * (1 + position_effect) + trend_adjustment\n","\n","        min_val = max(stats['min_non_zero'] * 0.8, 1)\n","        max_val = stats['mean_non_zero'] * 1.3\n","\n","    prediction = np.clip(prediction, min_val, max_val)\n","\n","    if stats['zero_pattern']['regular_spacing'] > 0.5:\n","        if stats['recent_value'] > 0:\n","            blend_factor = 0.6\n","            prediction = (prediction * blend_factor + stats['recent_value'] * (1 - blend_factor))\n","\n","    return round(prediction)\n","\n","def make_predictions(historical_data, n_periods=6):\n","    if len(historical_data) == 0:\n","        return np.zeros(n_periods)\n","\n","    try:\n","        stats = calculate_stats(historical_data)\n","    except:\n","        return np.zeros(n_periods)\n","\n","    predictions = []\n","    periods_since_non_zero = 0\n","\n","    for i in range(n_periods):\n","        try:\n","            if should_predict_zero(stats, i, periods_since_non_zero):\n","                pred = 0\n","                periods_since_non_zero += 1\n","            else:\n","                pred = predict_non_zero_value(stats, i, historical_data)\n","                periods_since_non_zero = 0\n","        except:\n","            pred = 0\n","\n","        predictions.append(pred)\n","\n","    return np.array(predictions)\n","\n","def calculate_error_metrics(actuals, predictions):\n","    zero_mask = actuals == 0\n","    non_zero_mask = ~zero_mask\n","\n","    zero_accuracy = np.mean(predictions[zero_mask] == 0) if np.any(zero_mask) else 1\n","\n","    if np.any(non_zero_mask):\n","        non_zero_mad = np.mean(np.abs(predictions[non_zero_mask] - actuals[non_zero_mask]))\n","        non_zero_mean = np.mean(actuals[non_zero_mask])\n","        mad_ratio = non_zero_mad / non_zero_mean if non_zero_mean > 0 else 0\n","    else:\n","        non_zero_mad = 0\n","        mad_ratio = 0\n","\n","    total_mad = np.mean(np.abs(predictions - actuals))\n","\n","    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n","\n","    return total_mad, mad_ratio, rmse\n","\n","def make_predictions_with_cv(historical_data, n_periods=6):\n","    predictions = []\n","    stats = calculate_stats(historical_data)\n","\n","    X, y = prepare_sliding_windows(historical_data, window_size=2)\n","\n","    if len(X) < 4:\n","        return make_predictions(historical_data, n_periods)\n","\n","    try:\n","        tscv = TimeSeriesSplit(n_splits=2)\n","        cv_predictions = []\n","\n","        for train_idx, val_idx in tscv.split(X):\n","            if len(train_idx) == 0 or len(val_idx) == 0:\n","                continue\n","\n","            X_train, X_val = X[train_idx], X[val_idx]\n","            y_train, y_val = y[train_idx], y[val_idx]\n","\n","            if len(X_train) < 2 or len(X_val) < 1:\n","                continue\n","\n","            scaler = StandardScaler()\n","            X_train_scaled = scaler.fit_transform(X_train)\n","            X_val_scaled = scaler.transform(X_val)\n","\n","            model = RegularizedPredictor(input_size=4)\n","            model = train_with_validation(\n","                model,\n","                X_train_scaled,\n","                y_train,\n","                epochs=100,\n","                batch_size=min(32, len(X_train))\n","            )\n","\n","            with torch.no_grad():\n","                model.eval()\n","                val_pred = model(torch.FloatTensor(X_val_scaled))\n","                cv_predictions.append(val_pred.numpy())\n","\n","        if cv_predictions:\n","            ensemble_predictions = np.mean(cv_predictions, axis=0)\n","        else:\n","            return make_predictions(historical_data, n_periods)\n","\n","    except Exception as e:\n","        print(f\"Cross-validation failed, falling back to simple prediction: {str(e)}\")\n","        return make_predictions(historical_data, n_periods)\n","\n","    for i in range(n_periods):\n","        if should_predict_zero(stats, i, len(predictions)):\n","            pred = 0\n","        else:\n","            if i < len(ensemble_predictions):\n","                pred = round(max(0, ensemble_predictions[i]))\n","            else:\n","                pred = predict_non_zero_value(stats, i, historical_data)\n","        predictions.append(pred)\n","\n","    return np.array(predictions)\n","\n","def process_skus_full_history(df):\n","    skus = df['sku'].unique()\n","    results = {}\n","\n","    for sku in skus:\n","        try:\n","            sku_data = np.abs(df[df['sku'] == sku]['demanda'].values)\n","\n","            if len(sku_data) < 4:\n","                print(f\"Warning: SKU {sku} has insufficient data points ({len(sku_data)})\")\n","                continue\n","\n","            full_history = sku_data.copy()\n","\n","            all_predictions = []\n","            for i in range(4, len(sku_data)):\n","                window_data = sku_data[i-4:i]\n","                if len(window_data) == 4:\n","                    try:\n","                        pred = make_predictions_with_cv(window_data, n_periods=1)[0]\n","                        all_predictions.append(pred)\n","                    except Exception as e:\n","                        print(f\"Warning: Prediction failed for window in SKU {sku}: {str(e)}\")\n","                        all_predictions.append(np.nan)\n","\n","            actual_for_comparison = sku_data[4:]\n","\n","            if len(all_predictions) > 0 and len(actual_for_comparison) > 0:\n","                valid_mask = ~np.isnan(all_predictions)\n","                valid_predictions = np.array(all_predictions)[valid_mask]\n","                valid_actuals = actual_for_comparison[valid_mask]\n","\n","                if len(valid_predictions) > 0:\n","                    mad = np.mean(np.abs(valid_actuals - valid_predictions))\n","                    non_zero_mask = valid_actuals != 0\n","                    if np.any(non_zero_mask):\n","                        mad_ratio = mad / np.mean(valid_actuals[non_zero_mask])\n","                    else:\n","                        mad_ratio = 0\n","                    rmse = np.sqrt(mean_squared_error(valid_actuals, valid_predictions))\n","                else:\n","                    mad = mad_ratio = rmse = 0\n","            else:\n","                mad = mad_ratio = rmse = 0\n","\n","            retention_data = sku_data[-4:]\n","            if len(retention_data) == 4:\n","                try:\n","                    predictions = make_predictions_with_cv(retention_data)\n","                    retention_predictions = predictions[:4]\n","                    additional_predictions = predictions[4:]\n","                except Exception as e:\n","                    print(f\"Warning: CV prediction failed for SKU {sku}, using simple prediction: {str(e)}\")\n","                    all_preds = make_predictions(retention_data, n_periods=6)\n","                    retention_predictions = all_preds[:4]\n","                    additional_predictions = all_preds[4:]\n","            else:\n","                retention_predictions = make_predictions(retention_data, n_periods=4)\n","                additional_predictions = make_predictions(retention_data, n_periods=2)[4:]\n","\n","            if len(retention_data) > 0 and len(retention_predictions) > 0:\n","                retention_mad, retention_mad_ratio, retention_rmse = calculate_error_metrics(\n","                    retention_data, retention_predictions\n","                )\n","            else:\n","                retention_mad = retention_mad_ratio = retention_rmse = 0\n","\n","            try:\n","                stats = calculate_stats(retention_data)\n","            except Exception as e:\n","                print(f\"Warning: Stats calculation failed for SKU {sku}: {str(e)}\")\n","                stats = {\n","                    'is_zero_heavy': False,\n","                    'is_stable': False,\n","                    'zero_pattern': {'zero_ratio': 0}\n","                }\n","\n","            results[sku] = {\n","                'Full_History': full_history,\n","                'Full_Predictions': all_predictions,\n","                'Full_MAD': mad,\n","                'Full_MAD/Mean': mad_ratio,\n","                'Full_RMSE': rmse,\n","\n","                'MAD': retention_mad,\n","                'MAD/Mean': retention_mad_ratio,\n","                'RMSE': retention_rmse,\n","                'Retention_Data': retention_data,\n","                'Retention_Predictions': retention_predictions,\n","                'Additional_Predictions': additional_predictions,\n","                'Is_Zero_Heavy': stats['is_zero_heavy'],\n","                'Is_Stable': stats['is_stable'],\n","                'Zero_Ratio': stats['zero_pattern']['zero_ratio'],\n","                'Data_Points': len(retention_data)\n","            }\n","\n","        except Exception as e:\n","            print(f\"Warning: Error processing SKU {sku}: {str(e)}\")\n","            continue\n","\n","    return results\n","def plot_predictions(results, output_dir='plots'):\n","    import os\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    plt.style.use('ggplot')\n","\n","    for sku, metrics in results.items():\n","        plt.figure(figsize=(12, 6))\n","\n","        periods = [f'Period {i+1}' for i in range(len(metrics['Retention_Data']))]\n","\n","        plt.plot(periods, metrics['Retention_Data'], 'b-o', label='Actual Data', linewidth=2)\n","        plt.plot(periods, metrics['Retention_Predictions'], 'r--o', label='Predictions', linewidth=2)\n","\n","        plt.title(f'Retention Data vs Predictions - SKU: {sku}')\n","        plt.xlabel('Period')\n","        plt.ylabel('Demand')\n","        plt.legend()\n","        plt.grid(True, alpha=0.3)\n","        plt.xticks(rotation=45)\n","\n","        for i, (actual, pred) in enumerate(zip(metrics['Retention_Data'], metrics['Retention_Predictions'])):\n","            plt.annotate(f'{actual:.0f}', (i, actual), textcoords=\"offset points\", xytext=(0,10), ha='center')\n","            plt.annotate(f'{pred:.0f}', (i, pred), textcoords=\"offset points\", xytext=(0,-15), ha='center')\n","\n","        plt.tight_layout()\n","        plt.savefig(f'{output_dir}/retention_comparison_{sku}.png', dpi=300, bbox_inches='tight')\n","        plt.close()\n","\n","        plt.figure(figsize=(12, 6))\n","\n","        all_periods = [f'Period {i+1}' for i in range(len(metrics['Retention_Data']) + len(metrics['Additional_Predictions']))]\n","\n","        plt.plot(all_periods[:len(metrics['Retention_Data'])],\n","                metrics['Retention_Data'],\n","                'b-o',\n","                label='Historical Data',\n","                linewidth=2)\n","\n","        all_predictions = np.concatenate([metrics['Retention_Predictions'], metrics['Additional_Predictions']])\n","        plt.plot(all_periods,\n","                all_predictions,\n","                'r--o',\n","                label='Predictions',\n","                linewidth=2)\n","\n","        plt.title(f'Full Demand Predictions - SKU: {sku}')\n","        plt.xlabel('Period')\n","        plt.ylabel('Demand')\n","        plt.legend()\n","        plt.grid(True, alpha=0.3)\n","        plt.xticks(rotation=45)\n","\n","        for i, pred in enumerate(all_predictions):\n","            if i < len(metrics['Retention_Data']):\n","                actual = metrics['Retention_Data'][i]\n","                plt.annotate(f'{actual:.0f}', (i, actual), textcoords=\"offset points\", xytext=(0,10), ha='center')\n","            plt.annotate(f'{pred:.0f}', (i, pred), textcoords=\"offset points\", xytext=(0,-15), ha='center')\n","\n","        plt.tight_layout()\n","        plt.savefig(f'{output_dir}/full_predictions_{sku}.png', dpi=300, bbox_inches='tight')\n","        plt.close()\n","def plot_full_history_predictions(results, output_dir='plots'):\n","    import os\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    plt.style.use('ggplot')\n","\n","    for sku, metrics in results.items():\n","        if len(metrics['Full_Predictions']) > 0:\n","            try:\n","                plt.figure(figsize=(15, 7))\n","\n","                full_history = metrics['Full_History']\n","                predictions = np.array(metrics['Full_Predictions'])\n","\n","                all_periods = [f'Period {i+1}' for i in range(len(full_history))]\n","                prediction_periods = all_periods[4:]\n","\n","                plt.plot(all_periods, full_history, 'b-o', label='Actual Data', linewidth=2)\n","\n","                valid_mask = ~np.isnan(predictions)\n","                if np.any(valid_mask):\n","                    valid_predictions = predictions[valid_mask]\n","                    valid_periods = [prediction_periods[i] for i in range(len(prediction_periods)) if valid_mask[i]]\n","                    plt.plot(valid_periods, valid_predictions, 'r--o', label='Predictions', linewidth=2)\n","\n","                plt.title(f'Full History Demand vs Predictions - SKU: {sku}\\nMAD/Mean: {metrics[\"Full_MAD/Mean\"]:.2f}, RMSE: {metrics[\"Full_RMSE\"]:.2f}')\n","                plt.xlabel('Period')\n","                plt.ylabel('Demand')\n","                plt.legend()\n","                plt.grid(True, alpha=0.3)\n","                plt.xticks(rotation=45)\n","\n","                for i, val in enumerate(full_history):\n","                    if not np.isnan(val):\n","                        plt.annotate(f'{val:.0f}', (i, val), textcoords=\"offset points\", xytext=(0,10), ha='center')\n","\n","                for i, pred in enumerate(predictions):\n","                    if not np.isnan(pred):\n","                        plt.annotate(f'{pred:.0f}', (i+4, pred), textcoords=\"offset points\", xytext=(0,-15), ha='center', color='red')\n","\n","                plt.tight_layout()\n","                plt.savefig(f'{output_dir}/full_history_comparison_{sku}.png', dpi=300, bbox_inches='tight')\n","                plt.close()\n","            except Exception as e:\n","                print(f\"Warning: Error plotting SKU {sku}: {str(e)}\")\n","\n","def main(file_path):\n","    try:\n","        df = pd.read_excel(file_path, usecols=['periodo', 'sku', 'demanda'])\n","        df['demanda'] = df['demanda'].abs()\n","\n","        results = process_skus_full_history(df)\n","\n","        plot_predictions(results)\n","        plot_full_history_predictions(results)\n","\n","        print(\"\\nResultados:\")\n","        for sku, metrics in results.items():\n","            try:\n","                print(f\"\\nSKU: {sku}\")\n","\n","                print(\"\\nMétricas de Retención (últimos 4 períodos):\")\n","                print(f\"MAD/Media: {metrics['MAD/Mean']:.2f}\")\n","                print(f\"RMSE: {metrics['RMSE']:.2f}\")\n","\n","                print(\"\\nPredicciones de Retención:\")\n","                for i, (actual, pred) in enumerate(zip(metrics['Retention_Data'], metrics['Retention_Predictions'])):\n","                    print(f\"Periodo {i+1}: Actual: {actual:.0f}, Predicción: {pred:.0f}\")\n","\n","                print(\"\\nPredicciones Adicionales:\")\n","                for i, pred in enumerate(metrics['Additional_Predictions'], start=5):\n","                    print(f\"Periodo {i}: Predicción: {pred:.0f}\")\n","\n","                print(\"\\nComparación de Historia Completa (36 períodos):\")\n","                print(\"Periodo  |  Actual  |  Predicción\")\n","                print(\"-\" * 40)\n","\n","                full_history = metrics['Full_History']\n","                full_predictions = metrics['Full_Predictions']\n","\n","                all_actuals = []\n","                all_predictions = []\n","\n","                for i in range(len(full_history)):\n","                    actual = full_history[i]\n","                    if i < 4:\n","                        available_data = full_history[:i+1]\n","                        pred = np.mean(available_data) if len(available_data) > 0 else actual\n","                    else:\n","                        pred = full_predictions[i-4] if i-4 < len(full_predictions) else actual\n","\n","                    print(f\"  {i+1:02d}    |   {actual:5.0f}  |    {pred:5.0f}\")\n","\n","                    all_actuals.append(actual)\n","                    all_predictions.append(pred)\n","\n","                all_actuals = np.array(all_actuals)\n","                all_predictions = np.array(all_predictions)\n","\n","                mad = np.mean(np.abs(all_actuals - all_predictions))\n","                mean_actual = np.mean(all_actuals)\n","                mad_mean_ratio = mad / mean_actual if mean_actual > 0 else 0\n","\n","                rmse = np.sqrt(np.mean((all_actuals - all_predictions) ** 2))\n","\n","                print(\"-\" * 50)\n","                print(f\"MAD/Media: {mad_mean_ratio:.2f}\")\n","                print(f\"RMSE: {rmse:.2f}\")\n","\n","                print(f\"MAD/Media: {metrics['Full_MAD/Mean']:.2f}\")\n","                print(f\"RMSE: {metrics['Full_RMSE']:.2f}\")\n","                print(\"-\" * 50)\n","            except Exception as e:\n","                print(f\"Warning: Error printing results for SKU {sku}: {str(e)}\")\n","\n","        print(\"\\nGráficas se encuentran en 'plots'.\")\n","\n","    except Exception as e:\n","        print(f\"Error: {str(e)}\")\n","\n","if __name__ == \"__main__\":\n","    file_path = 'https://github.com/Dabut6412/Forecast-IA/raw/refs/heads/main/FNN/demanda.xlsx'\n","    main(file_path)"]},{"cell_type":"code","source":["import sys\n","print(sys.version)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wA9eZXeOQp-5","executionInfo":{"status":"ok","timestamp":1731798953334,"user_tz":360,"elapsed":187,"user":{"displayName":"Daniel Brizuela","userId":"00306628851259003269"}},"outputId":"f40fcb51-9300-474e-c2b8-2f0cb95db852"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n"]}]},{"cell_type":"code","source":["import pkg_resources\n","\n","for package in ['pandas', 'numpy', 'torch', 'sklearn', 'matplotlib']:\n","  try:\n","    version = pkg_resources.get_distribution(package).version\n","    print(f'{package}=={version}')\n","  except pkg_resources.DistributionNotFound:\n","    print(f'{package}: No instalado')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WY-iSrr1S63_","executionInfo":{"status":"ok","timestamp":1731799529667,"user_tz":360,"elapsed":379,"user":{"displayName":"Daniel Brizuela","userId":"00306628851259003269"}},"outputId":"d904d787-fbe8-4479-c492-da68441b02b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pandas==2.2.2\n","numpy==1.26.4\n","torch==2.5.1+cu121\n","sklearn: No instalado\n","matplotlib==3.8.0\n"]}]}]}